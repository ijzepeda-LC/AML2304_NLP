{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f9842b",
   "metadata": {},
   "source": [
    "Este notebook,  \n",
    "\n",
    "convierte los ratings a integers.  \n",
    "\n",
    " hace un preprocesamiento a la columna de contenido: tokens, stopwords, remove punctuation, back to string  \n",
    "\n",
    "Hace un separacion de entrenamiento y prueba de 75,25, y stratify en ratings, para que tome parejo de cada categoria.  \n",
    "Se usa TfidfVectorizer, para complementar el preprocesamiento, el cual tambien hace una limpieza de stopwords. toma 5000 palabras mas usadas, convierte a lowercase, remueve acentos no unicode, y usa unigramas y bigramas\n",
    "\n",
    "Se entrenan varios modelos de Regresion, y Clasificacion.  \n",
    "Aparte de las metricas elaboradas, hice unas pruebas manuales, con texto extraido o manual,  \n",
    "Se deja un threshold de 3 puntos para considerarlo correcto.  \n",
    "ya que son valores subjetivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe1ee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e28d245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pale imitation of better films</td>\n",
       "      <td>Three words: \"Cool Hand Luke.\"  Same film, don...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Didactic and overlong</td>\n",
       "      <td>Another one of those overlong morally right-on...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mediocre people reward mediocre cinema.</td>\n",
       "      <td>It bugs me that this movie is rated so high- n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The plain &amp; simple truth. It doesn\\'t deserve ...</td>\n",
       "      <td>just read the title. Tough I think it's a pret...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not the greatest movie of all time</td>\n",
       "      <td>Shawshank is nothing more than a fairy tale.  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20306</th>\n",
       "      <td>extremely scary</td>\n",
       "      <td>peter Lorre is the best child serial killer ci...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20307</th>\n",
       "      <td>Classic Mystery</td>\n",
       "      <td>I thoroughly enjoyed watching this film. Seein...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20308</th>\n",
       "      <td>One of the most influential films ever, almost...</td>\n",
       "      <td>One of the most influential films ever, almost...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20309</th>\n",
       "      <td>M a few thoughts</td>\n",
       "      <td>I will not take time to praise the film, as ot...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20310</th>\n",
       "      <td>Still a remarkably powerful film.</td>\n",
       "      <td>If you found Todd Solendz's recent film \"Happi...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20311 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "0                         Pale imitation of better films   \n",
       "1                                  Didactic and overlong   \n",
       "2                Mediocre people reward mediocre cinema.   \n",
       "3      The plain & simple truth. It doesn\\'t deserve ...   \n",
       "4                     Not the greatest movie of all time   \n",
       "...                                                  ...   \n",
       "20306                                    extremely scary   \n",
       "20307                                    Classic Mystery   \n",
       "20308  One of the most influential films ever, almost...   \n",
       "20309                                   M a few thoughts   \n",
       "20310                  Still a remarkably powerful film.   \n",
       "\n",
       "                                                 content  rating  \n",
       "0      Three words: \"Cool Hand Luke.\"  Same film, don...       1  \n",
       "1      Another one of those overlong morally right-on...       1  \n",
       "2      It bugs me that this movie is rated so high- n...       1  \n",
       "3      just read the title. Tough I think it's a pret...       1  \n",
       "4      Shawshank is nothing more than a fairy tale.  ...       1  \n",
       "...                                                  ...     ...  \n",
       "20306  peter Lorre is the best child serial killer ci...      10  \n",
       "20307  I thoroughly enjoyed watching this film. Seein...      10  \n",
       "20308  One of the most influential films ever, almost...      10  \n",
       "20309  I will not take time to praise the film, as ot...      10  \n",
       "20310  If you found Todd Solendz's recent film \"Happi...      10  \n",
       "\n",
       "[20311 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw=pd.read_csv('reviews.csv')\n",
    "df = df_raw[['title','content','rating']]\n",
    "df.head()\n",
    "\n",
    "\n",
    "df = df[~df['rating'].isna()]\n",
    "df['rating']=[int(x.split('/')[0]) for x in df['rating']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4510a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "title      0\n",
      "content    0\n",
      "rating     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9     2496\n",
       "8     2493\n",
       "10    2492\n",
       "7     2432\n",
       "6     2202\n",
       "5     1925\n",
       "1     1790\n",
       "4     1612\n",
       "3     1489\n",
       "2     1380\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.isna().sum())\n",
    "\n",
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6936591b",
   "metadata": {},
   "source": [
    "# Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d9a7c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stopword = stopwords.words('english')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.replace('\\n','. ')\n",
    "    return text\n",
    "\n",
    "def remove_punct(text, lower=False):\n",
    "    if(type(text)==str):\n",
    "        text = text.replace('\\n','. ')\n",
    "        text = text.replace(',',' ').replace('!','').replace('?',' ')\n",
    "        text = text.replace('.',' ').replace('#','').replace('$',' ')\n",
    "        text = text.replace('^',' ').replace('&','and').replace(';',' ')\n",
    "        text = text.replace('  ',' ')\n",
    "        return text\n",
    "    elif(type(text)==list):\n",
    "        _words=[]\n",
    "        for w in text:\n",
    "            if w.isalnum():\n",
    "                _words.append(w if not lower else w.lower())\n",
    "#         print('remove_punct',len(_words))\n",
    "        return _words\n",
    "\n",
    "def get_sentences(text):\n",
    "    return sent_tokenize(text)\n",
    "\n",
    "def get_tokens(text):\n",
    "    words =[]\n",
    "    for w in word_tokenize(text):\n",
    "        if w.isalnum():\n",
    "            words.append(w)\n",
    "    return words\n",
    "    \n",
    "\n",
    "def remove_stopwords(words):\n",
    "    just_words=[]\n",
    "    for word in words:\n",
    "        if word.lower() not in stopword:\n",
    "            just_words.append(word)\n",
    "#     print('just_words',len(just_words))\n",
    "    return just_words\n",
    "    \n",
    "    \n",
    "def lemmatize(text):\n",
    "    record_lemmatized = [lemmatizer.lemmatize(token) for token in text]\n",
    "    return record_lemmatized\n",
    "    \n",
    "    \n",
    "def list_to_string(ls):\n",
    "    return \" \".join(ls)\n",
    "    \n",
    "# clean words: boooook\n",
    "# Remove non stop words of 2 letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76478f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning approach 1:\n",
    "    # tokenize everything, remove stop words, lower all, remove punctutation\n",
    "\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def preprocess_text_ap1(x):\n",
    "       # tokenize everything, remove stop words, lower all, remove punctutation\n",
    "    # set tokens each description\n",
    "    dataset_tokens= get_tokens(x)\n",
    "    # remove stopwords\n",
    "    dataset_nostopwords= remove_stopwords(dataset_tokens)\n",
    "    # remove punctuation\n",
    "    dataset_main_words= remove_punct(dataset_nostopwords, lower=False)\n",
    "    # Lower all\n",
    "    # dataset_main_words_lower=[x.lower() for x in dataset_main_words]\n",
    "    # Back to string\n",
    "    dataset_clean_text =  list_to_string(dataset_main_words)\n",
    "    return dataset_clean_text\n",
    "\n",
    "\n",
    "dataset_clean_text = [preprocess_text_ap1(x) for x in df['content']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec77a09b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>rating</th>\n",
       "      <th>content_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pale imitation of better films</td>\n",
       "      <td>Three words: \"Cool Hand Luke.\"  Same film, don...</td>\n",
       "      <td>1</td>\n",
       "      <td>Three words Cool Hand Luke film done better do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Didactic and overlong</td>\n",
       "      <td>Another one of those overlong morally right-on...</td>\n",
       "      <td>1</td>\n",
       "      <td>Another one overlong morally movies never rise...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mediocre people reward mediocre cinema.</td>\n",
       "      <td>It bugs me that this movie is rated so high- n...</td>\n",
       "      <td>1</td>\n",
       "      <td>bugs movie rated bad movie mediocre one Appare...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The plain &amp; simple truth. It doesn\\'t deserve ...</td>\n",
       "      <td>just read the title. Tough I think it's a pret...</td>\n",
       "      <td>1</td>\n",
       "      <td>read title Tough think pretty decent movie goo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Not the greatest movie of all time</td>\n",
       "      <td>Shawshank is nothing more than a fairy tale.  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Shawshank nothing fairy tale tells us much pri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                     Pale imitation of better films   \n",
       "1                              Didactic and overlong   \n",
       "2            Mediocre people reward mediocre cinema.   \n",
       "3  The plain & simple truth. It doesn\\'t deserve ...   \n",
       "4                 Not the greatest movie of all time   \n",
       "\n",
       "                                             content  rating  \\\n",
       "0  Three words: \"Cool Hand Luke.\"  Same film, don...       1   \n",
       "1  Another one of those overlong morally right-on...       1   \n",
       "2  It bugs me that this movie is rated so high- n...       1   \n",
       "3  just read the title. Tough I think it's a pret...       1   \n",
       "4  Shawshank is nothing more than a fairy tale.  ...       1   \n",
       "\n",
       "                                       content_clean  \n",
       "0  Three words Cool Hand Luke film done better do...  \n",
       "1  Another one overlong morally movies never rise...  \n",
       "2  bugs movie rated bad movie mediocre one Appare...  \n",
       "3  read title Tough think pretty decent movie goo...  \n",
       "4  Shawshank nothing fairy tale tells us much pri...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content_clean']=dataset_clean_text\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfb66af",
   "metadata": {},
   "source": [
    "# METHOD 1 TFIDF\n",
    "\n",
    "compare to a manual method  \n",
    "separate the test-train in equal samples\n",
    "\n",
    "The training was giving a lot of 8+ ratings. I rerun this with stratify\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84795c50",
   "metadata": {},
   "source": [
    "# Original data\n",
    "hace el entrenamiento con el contenido original o el preprocesado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cc64930",
   "metadata": {},
   "outputs": [],
   "source": [
    "original=False\n",
    "\n",
    "# Assuming you have a list of movie reviews and their corresponding ratings\n",
    "if original:\n",
    "    reviews = df['content']\n",
    "    ratings = df['rating']\n",
    "else:\n",
    "    reviews = df['content_clean']#dataset_clean_text\n",
    "    ratings = df['rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d14d77",
   "metadata": {},
   "source": [
    "### Dummy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d2c5e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "_reviews=[\n",
    "    \"Was this a missed warning sign? The current climate in America is kind of portayed here. Though some would argue, that it doesn't depict all of America, not even just the one side who seems to have a glutton for punishment and seems to like to vote against their own interests. So while there is some relevance to current events, this go far out.Still if you feel uneasy watching this, it doesn't mean something is wrong with you. Quite the opposite is the case, everything is right with you. Quite ridiculous at times, it is there for entertainment purposes ... no really! They weren't trying to do a documentary! All kidding aside, this can be viewed as fun - no matter what your political background is.\",\n",
    "    \"Imagine what you'd do, when you wake from a bad dream, to find you're held by four square walls, for as long as someone deems. No idea why you're trapped, what you've done, why you're kidnapped, just a ceaseless line of dumplings going down your gyoza hatch. Now some fifteen years have passed, every question has been asked, and you're suddenly set free, can start your own avenging spree. Before you do you need to feed, by eating something that's in need, so an octopus is ordered, and head first you cross the borders. But things aren't what they might seem, tied and tethered and undreamed, as the puppet master hovers, manipulates what you'll discover. Some films you cannot watch too often and this is one of the greatest pieces of cinematic brilliance ever created.\",\n",
    "    \"Eugenics is the study and practice of selective breeding applied to humans, with the aim of improving the species. In a historical and broader sense, eugenics can also be a study of \\\"improving human genetic qualities. \\\"Advocates of eugenics sought to counter what they regarded as spoiler of genetics dynamics within the human gene pool, specifically in regard to congenital disorders and factors relating to the heritability of IQ. This movie is a clear eugenics message. That's to say Eugencists are Striking Back. And Eugenics is totally unethical, and leads to racism.\",\n",
    "    \"\"\"I find it a bit ironic that a movie about the dumbing down of America sums up the message in the first few minutes and then spends nearly 90 minutes repeating the same jokes to get the point across. The message is a bit frighteningly on point in a time when, what seem to be, complete idiots on social media make millions. And I'm guessing many of us have known families like both that were portrayed at the start. I think those two things gain this movie a lot of its accolades despite the 'story'. It had its moments here and there, but as a whole it wasn't as great as the hype.\"\"\",\n",
    "    \"\"\"The story of the movie is just perfect. All futuristic movies describe an advanced civilization. This movie chooses the other way around, outsmarting all other super-advanced-Hollywood-fictional-hi-tech scripts. May be movie was supposed to be rated with \"R+\"; the emphasis on sex-related \"humor\" is off the charts. In my opinion, the prime target for the movie is below 14 years of age, like may be 12. It definitely doesn't address for 25+ people. It's not funny at all, I don't remember I have laughed even once. Story is short; he solves exactly one problem. I think this story could be expressed in far better ways than this movie. It's a brilliant idea, but bad screenplay. Movie tried to tell \"how stupid can we get\" in a stupid (or, may be, \"poor\") way. From this point of view, it's successful; it's all about stupid stuff, and it's all told in stupid way. I, however, still believe that it could be a movie that still shows \"how stupid can we get\" in a smarter way. As a conclusion; it's recommended to be watched but don't expect real comedy or smart jokes. Don't try to watch during your romantic moments, not to mention keep this movie away from your children.\"\"\",\n",
    "    \"\"\"I hate indian movies they're garbage just terrible I mean seriously all these singing, dancing and all the dramatic crying they all look the same to me BUT this is the only movie which I liked original screenplay absolutely flawless movie by a genius director I still can't believe this is indian movie highly recommended for horror genre fans\"\"\",\n",
    "    \"\"\"Tumbbad is not a common movie. It will leave you gripped to your seat making you think \"what would happen next\". Whole movie is so beautifully shot no wonder it is shot in natural light and the beauty is visible. This movie is a feast for your eyes with cinematic excellence is on full display. You wouldnt even have time to wander off your mind but watch it with eyes wide open. You won't enjoy it on small screen but have to watch in cinema halls. Mind you this movie took 6 years in making can you believe in the perseverance of the people who clung onto movie for 6 years despite harships.\"\"\",\n",
    "    \"\"\"Tumbbad is IMO the best Indian horror movie ever, with a strong script and incredibly good shadowy visuals and great sound design (although I will cut a point for the loud RGV-esque background score). Focused direction and a solid lead performance from Sohum Shah (who also produced the film).\"\"\",\n",
    "    \n",
    "\"This is one of my most favorite movies, I have enjoyed every aspect of it, from camera, script, effects, and music. All is perfect\",\n",
    "    \"This was a waste of time; Everything was not good, music, dialogue, characters, screeplany. I wish I have spent my time better\",\n",
    "    \"I am sad I haven't knew about this movie before. It has everything on it, not just for a nische, but for everyone.\",\n",
    "\"\"\"This show has a beginning and an actual ending. Not every show can offer that. This TV show is underrated and that's a shame. People need to watch this!\"\"\",\n",
    "         \"\"\"Replicating the 90s movie was tough, I acknowledge that.\n",
    "However, one thing stroke me and I won't be watching any more episodes (currently at s1e10): They find Pieters (the virus' creator) in the container, and there is no mention-not even a thought- about asking him about the cure or having him work on a vaccine.\n",
    "She was point-blank ready to shoot him, I mean, that was the point where it became obvious that the whole series had been designed to draaaag and draaaag and draaaag. Absolutely no credibility.\n",
    "What I would expect from a 12 monkeys tv series after so many years, would be to have the opportunity to dive into the whole 12 monkeys dystopian universe, learn more about the characters and a bit more details about the twists in the original motion picture.\n",
    "Really loving the effort from the cast. From a director's stand-point, its not awesome but its not bad. But in terms of script, the whole thing is too messed up, overly complicated, overly paced and really why they didn't ask Pieters the cure or have him work on the vaccine?\n",
    "Seriously, I wish the creators of Dark had gotten their hands on the script and the realization as a whole.\"\"\",\n",
    "         \n",
    "]\n",
    "_ratings=[\n",
    "    7,\n",
    "    10,\n",
    "    1,\n",
    "    4,\n",
    "    1,\n",
    "    8,\n",
    "    10,\n",
    "    9,\n",
    "    9,\n",
    "    1,\n",
    "    10,\n",
    "    9,\n",
    "    3\n",
    "]\n",
    "\n",
    "results={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85f1e0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test models\n",
    "\n",
    "def test_model(name,_model, thresh=3):\n",
    "    print(\"\\n\\n========================\\n\",name,'\\nThreshold: ',thresh,'\\n========================')\n",
    "    correct=0\n",
    "    incorrect=0\n",
    "    for review_test,rating_test in zip(_reviews,_ratings):\n",
    "        X_test_tfidf = vectorizer.transform([review_test])\n",
    "        predicted_rating = _model.predict(X_test_tfidf)\n",
    "        print(f\"Predicted: {'{:.2f}'.format(predicted_rating[0])} of {rating_test}\\t\", end=\"\")\n",
    "        #print(f\"Predicted: {math.floor(predicted_rating[0])} of {rating_test}\")\n",
    "        if(abs(predicted_rating[0]-rating_test)<=thresh):\n",
    "            correct=correct+1\n",
    "            print(\"✅\")\n",
    "        else:\n",
    "            incorrect=incorrect+1\n",
    "            print(\"❌\")\n",
    "    total=round((correct/len(_reviews))*100, 3)\n",
    "    print(f\"\\n✅ Correct:{correct}\\n❌ Incorrect:{incorrect}\\nTotal: {len(_reviews)}=> {total:.2f}%\")\n",
    "    return name, total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093aba11",
   "metadata": {},
   "source": [
    "#  \n",
    "# Split Data & TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf95bec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "    \n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(reviews, ratings, test_size=0.25, random_state=42, stratify=ratings)\n",
    "\n",
    "\n",
    "# Create a TF-IDF vectorizer with preprocessing options\n",
    "vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    strip_accents='unicode',\n",
    "    stop_words='english',\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=5000 # features made by term frequency\n",
    ")\n",
    "\n",
    "# Fit the vectorizer on the training reviews and transform the data\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d9f135",
   "metadata": {},
   "source": [
    "#  \n",
    "# Models - Regression\n",
    "\n",
    "## RIDGE  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8e59be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 4.526832615218386\n",
      "Mean Absolute Error: 1.6994196562709072\n",
      "Cross-Validated MSE: 4.471946266049071\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Pre-Processed:\\nMean Squared Error: 4.444501189186152\\nMean Absolute Error: 1.6877876810286814\\nCross-Validated MSE: 4.424840704022955'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a Ridge regression model with regularization\n",
    "ridge_regressor = Ridge(alpha=0.5)\n",
    "\n",
    "# Train the Ridge regression model\n",
    "ridge_regressor.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict ratings for the testing reviews\n",
    "ridge_y_pred = ridge_regressor.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model using mean squared error (MSE) and mean absolute error (MAE)\n",
    "mse = mean_squared_error(y_test, ridge_y_pred)\n",
    "mae = mean_absolute_error(y_test, ridge_y_pred)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n",
    "# Perform cross-validation to get a more robust performance estimate\n",
    "cv_scores = cross_val_score(ridge_regressor, X_train_tfidf, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_mse = -cv_scores.mean()\n",
    "print(\"Cross-Validated MSE:\", cv_mse)\n",
    "\n",
    "\"\"\"Pre-Processed:\n",
    "Mean Squared Error: 4.444501189186152\n",
    "Mean Absolute Error: 1.6877876810286814\n",
    "Cross-Validated MSE: 4.424840704022955\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1508157",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "# Decision Tree Regression\n",
    "# Random Forest Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6782b23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression MSE: 5.4554981402003095\n",
      "Linear Regression MAE: 1.8667115843379707\n",
      "Decision Tree Regression MSE: 10.96089886657039\n",
      "Decision Tree Regression MAE: 2.539319942234475\n",
      "Random Forest Regression MSE: 5.444089617139831\n",
      "Random Forest Regression MAE: 1.8683756754670549\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "# Linear Regression\n",
    "linear_regression = LinearRegression()\n",
    "linear_regression.fit(X_train_tfidf, y_train)\n",
    "linear_regression_predictions = linear_regression.predict(X_test_tfidf)\n",
    "linear_regression_mse = mean_squared_error(y_test, linear_regression_predictions)\n",
    "linear_regression_mae = mean_absolute_error(y_test, linear_regression_predictions)\n",
    "\n",
    "# Decision Tree Regression\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "decision_tree.fit(X_train_tfidf, y_train)\n",
    "decision_tree_predictions = decision_tree.predict(X_test_tfidf)\n",
    "decision_tree_mse = mean_squared_error(y_test, decision_tree_predictions)\n",
    "decision_tree_mae = mean_absolute_error(y_test, decision_tree_predictions)\n",
    "\n",
    "# Random Forest Regression\n",
    "random_forest = RandomForestRegressor()\n",
    "random_forest.fit(X_train_tfidf, y_train)\n",
    "random_forest_predictions = random_forest.predict(X_test_tfidf)\n",
    "random_forest_mse = mean_squared_error(y_test, random_forest_predictions)\n",
    "random_forest_mae = mean_absolute_error(y_test, random_forest_predictions)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Linear Regression MSE:\", linear_regression_mse)\n",
    "print(\"Linear Regression MAE:\", linear_regression_mae)\n",
    "print(\"Decision Tree Regression MSE:\", decision_tree_mse)\n",
    "print(\"Decision Tree Regression MAE:\", decision_tree_mae)\n",
    "print(\"Random Forest Regression MSE:\", random_forest_mse)\n",
    "print(\"Random Forest Regression MAE:\", random_forest_mae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d81b4f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "========================\n",
      " Ridge Regression \n",
      "Threshold:  3 \n",
      "========================\n",
      "Predicted: 2.98 of 7\t❌\n",
      "Predicted: 9.76 of 10\t✅\n",
      "Predicted: 3.77 of 1\t✅\n",
      "Predicted: 6.28 of 4\t✅\n",
      "Predicted: 4.48 of 1\t❌\n",
      "Predicted: 6.32 of 8\t✅\n",
      "Predicted: 8.51 of 10\t✅\n",
      "Predicted: 6.78 of 9\t✅\n",
      "Predicted: 8.93 of 9\t✅\n",
      "Predicted: 1.81 of 1\t✅\n",
      "Predicted: 6.75 of 10\t❌\n",
      "Predicted: 4.13 of 9\t❌\n",
      "Predicted: 3.26 of 3\t✅\n",
      "\n",
      "✅ Correct:9\n",
      "❌ Incorrect:4\n",
      "Total: 13=> 69.23%\n",
      "\n",
      "\n",
      "========================\n",
      " Linear Regression \n",
      "Threshold:  3 \n",
      "========================\n",
      "Predicted: 1.92 of 7\t❌\n",
      "Predicted: 10.35 of 10\t✅\n",
      "Predicted: 2.15 of 1\t✅\n",
      "Predicted: 5.87 of 4\t✅\n",
      "Predicted: 4.42 of 1\t❌\n",
      "Predicted: 6.91 of 8\t✅\n",
      "Predicted: 8.58 of 10\t✅\n",
      "Predicted: 6.40 of 9\t✅\n",
      "Predicted: 8.90 of 9\t✅\n",
      "Predicted: 2.03 of 1\t✅\n",
      "Predicted: 7.08 of 10\t✅\n",
      "Predicted: 3.68 of 9\t❌\n",
      "Predicted: 2.76 of 3\t✅\n",
      "\n",
      "✅ Correct:10\n",
      "❌ Incorrect:3\n",
      "Total: 13=> 76.92%\n",
      "\n",
      "\n",
      "========================\n",
      " Decision tree Regression \n",
      "Threshold:  3 \n",
      "========================\n",
      "Predicted: 1.00 of 7\t❌\n",
      "Predicted: 10.00 of 10\t✅\n",
      "Predicted: 5.00 of 1\t❌\n",
      "Predicted: 5.00 of 4\t✅\n",
      "Predicted: 6.00 of 1\t❌\n",
      "Predicted: 2.00 of 8\t❌\n",
      "Predicted: 10.00 of 10\t✅\n",
      "Predicted: 9.00 of 9\t✅\n",
      "Predicted: 2.00 of 9\t❌\n",
      "Predicted: 1.00 of 1\t✅\n",
      "Predicted: 7.00 of 10\t✅\n",
      "Predicted: 5.00 of 9\t❌\n",
      "Predicted: 9.00 of 3\t❌\n",
      "\n",
      "✅ Correct:6\n",
      "❌ Incorrect:7\n",
      "Total: 13=> 46.15%\n",
      "\n",
      "\n",
      "========================\n",
      " Random forest Regression \n",
      "Threshold:  3 \n",
      "========================\n",
      "Predicted: 5.22 of 7\t✅\n",
      "Predicted: 8.71 of 10\t✅\n",
      "Predicted: 5.39 of 1\t❌\n",
      "Predicted: 5.45 of 4\t✅\n",
      "Predicted: 5.25 of 1\t❌\n",
      "Predicted: 2.53 of 8\t❌\n",
      "Predicted: 6.38 of 10\t❌\n",
      "Predicted: 7.97 of 9\t✅\n",
      "Predicted: 9.02 of 9\t✅\n",
      "Predicted: 2.03 of 1\t✅\n",
      "Predicted: 7.07 of 10\t✅\n",
      "Predicted: 4.16 of 9\t❌\n",
      "Predicted: 6.03 of 3\t❌\n",
      "\n",
      "✅ Correct:7\n",
      "❌ Incorrect:6\n",
      "Total: 13=> 53.85%\n"
     ]
    }
   ],
   "source": [
    "# Test models on dummy data\n",
    "    \n",
    "models={\"Ridge Regression\":ridge_regressor,\"Linear Regression\":linear_regression, \"Decision tree Regression\":decision_tree,\"Random forest Regression\": random_forest}\n",
    "\n",
    "for name,model in models.items():\n",
    "    n,t = test_model(name,model)\n",
    "    results[n]=t\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77df6042",
   "metadata": {},
   "source": [
    "#  \n",
    "#  \n",
    "# CLasiffication\n",
    "\n",
    "#  \n",
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19ef169c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.22449783379283184\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Train the Random Forest model\n",
    "rf_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "rf_predictions = rf_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "rf_accuracy = accuracy_score(y_test, rf_predictions)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Random Forest Accuracy:\", rf_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9d8c25",
   "metadata": {},
   "source": [
    "### NEural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90eb0383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network (MLP) Accuracy: 0.19791256400157542\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Create a multilayer perceptron classifier\n",
    "mlp_classifier = MLPClassifier(hidden_layer_sizes=(100, 50), activation='relu', random_state=42)\n",
    "\n",
    "# Train the MLP model\n",
    "mlp_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "mlp_predictions = mlp_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "mlp_accuracy = accuracy_score(y_test, mlp_predictions)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"Neural Network (MLP) Accuracy:\", mlp_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d898c94",
   "metadata": {},
   "source": [
    "### KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f7342576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.12760929499803073\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a KNN classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "# Train the KNN model\n",
    "knn_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "knn_predictions = knn_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "knn_accuracy = accuracy_score(y_test, knn_predictions)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"KNN Accuracy:\", knn_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b399e76a",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f52e0830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.23079952737298148\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "\n",
    "# Train the SVM model\n",
    "svm_classifier.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "svm_predictions = svm_classifier.predict(X_test_tfidf)\n",
    "\n",
    "# Calculate accuracy\n",
    "svm_accuracy = accuracy_score(y_test, svm_predictions)\n",
    "\n",
    "# Print the accuracy\n",
    "print(\"SVM Accuracy:\", svm_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106257b9",
   "metadata": {},
   "source": [
    "## Test Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4b5d2b48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "========================\n",
      " SVM \n",
      "Threshold:  3 \n",
      "========================\n",
      "Predicted: 7.00 of 7\t✅\n",
      "Predicted: 10.00 of 10\t✅\n",
      "Predicted: 6.00 of 1\t❌\n",
      "Predicted: 7.00 of 4\t✅\n",
      "Predicted: 2.00 of 1\t✅\n",
      "Predicted: 4.00 of 8\t❌\n",
      "Predicted: 10.00 of 10\t✅\n",
      "Predicted: 8.00 of 9\t✅\n",
      "Predicted: 10.00 of 9\t✅\n",
      "Predicted: 1.00 of 1\t✅\n",
      "Predicted: 4.00 of 10\t❌\n",
      "Predicted: 3.00 of 9\t❌\n",
      "Predicted: 3.00 of 3\t✅\n",
      "\n",
      "✅ Correct:9\n",
      "❌ Incorrect:4\n",
      "Total: 13=> 69.23%\n",
      "\n",
      "\n",
      "========================\n",
      " KNN \n",
      "Threshold:  3 \n",
      "========================\n",
      "Predicted: 4.00 of 7\t✅\n",
      "Predicted: 1.00 of 10\t❌\n",
      "Predicted: 7.00 of 1\t❌\n",
      "Predicted: 5.00 of 4\t✅\n",
      "Predicted: 1.00 of 1\t✅\n",
      "Predicted: 4.00 of 8\t❌\n",
      "Predicted: 10.00 of 10\t✅\n",
      "Predicted: 5.00 of 9\t❌\n",
      "Predicted: 5.00 of 9\t❌\n",
      "Predicted: 1.00 of 1\t✅\n",
      "Predicted: 4.00 of 10\t❌\n",
      "Predicted: 1.00 of 9\t❌\n",
      "Predicted: 9.00 of 3\t❌\n",
      "\n",
      "✅ Correct:5\n",
      "❌ Incorrect:8\n",
      "Total: 13=> 38.46%\n",
      "\n",
      "\n",
      "========================\n",
      " Neural Network \n",
      "Threshold:  3 \n",
      "========================\n",
      "Predicted: 3.00 of 7\t❌\n",
      "Predicted: 10.00 of 10\t✅\n",
      "Predicted: 4.00 of 1\t✅\n",
      "Predicted: 7.00 of 4\t✅\n",
      "Predicted: 2.00 of 1\t✅\n",
      "Predicted: 4.00 of 8\t❌\n",
      "Predicted: 10.00 of 10\t✅\n",
      "Predicted: 8.00 of 9\t✅\n",
      "Predicted: 10.00 of 9\t✅\n",
      "Predicted: 1.00 of 1\t✅\n",
      "Predicted: 7.00 of 10\t✅\n",
      "Predicted: 3.00 of 9\t❌\n",
      "Predicted: 2.00 of 3\t✅\n",
      "\n",
      "✅ Correct:10\n",
      "❌ Incorrect:3\n",
      "Total: 13=> 76.92%\n",
      "\n",
      "\n",
      "========================\n",
      " Random forest C \n",
      "Threshold:  3 \n",
      "========================\n",
      "Predicted: 8.00 of 7\t✅\n",
      "Predicted: 10.00 of 10\t✅\n",
      "Predicted: 7.00 of 1\t❌\n",
      "Predicted: 7.00 of 4\t✅\n",
      "Predicted: 1.00 of 1\t✅\n",
      "Predicted: 1.00 of 8\t❌\n",
      "Predicted: 10.00 of 10\t✅\n",
      "Predicted: 8.00 of 9\t✅\n",
      "Predicted: 10.00 of 9\t✅\n",
      "Predicted: 1.00 of 1\t✅\n",
      "Predicted: 7.00 of 10\t✅\n",
      "Predicted: 1.00 of 9\t❌\n",
      "Predicted: 7.00 of 3\t❌\n",
      "\n",
      "✅ Correct:9\n",
      "❌ Incorrect:4\n",
      "Total: 13=> 69.23%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "models={\"SVM Classification\":svm_classifier,\"KNN Classification\":knn_classifier, \"Neural Network Classification\":mlp_classifier,\"Random forest Classification\": rf_classifier}\n",
    "\n",
    "for name,model in models.items():\n",
    "    n,t=test_model(name,model)\n",
    "    results[n]=t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ed849a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1b4f1e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ridge Regression': 69.231,\n",
       " 'Linear Regression': 76.923,\n",
       " 'Decision tree Regression': 46.154,\n",
       " 'Random forest Regression': 53.846,\n",
       " 'SVM': 69.231,\n",
       " 'KNN': 38.462,\n",
       " 'Neural Network': 76.923,\n",
       " 'Random forest C': 69.231}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e0a2f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6d7d59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e4befb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
