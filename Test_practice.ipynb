{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8c3c089",
   "metadata": {},
   "source": [
    "# Module 6\n",
    "## Vader Sentiment Analysis\n",
    "\n",
    "Compound score is a metric that calculates the sum of all the lexicon ratings which have been normalized -1 1  \n",
    "positive sentiment >=0.5  \n",
    "neutral sentiment <0.5 & -0.5>  \n",
    "negative <= -0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e4db9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9bce25c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.566, 'pos': 0.434, 'compound': 0.3182}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"The car is cool.\"\n",
    "analyzer.polarity_scores(sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7918fb1",
   "metadata": {},
   "source": [
    "### Vader Key Points\n",
    "- punctuations:  `the car is cool!!`\n",
    "- capitalizations `The car is COOL!!`\n",
    "- degree modifiers `The car is a bit Cool.`\n",
    "- conjuntions `The car is cool, but small.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bf7ccf",
   "metadata": {},
   "source": [
    "# Tri-gram\n",
    "Is a modifier that precedes the sentiment-LADEN (sentiment-ðŸ‘³ðŸ½â€â™‚ï¸) lexical feature, and have huge impact on the sentiment.  \n",
    "usually increase the negativity  \n",
    "like `not that`\n",
    "\n",
    "\"your hotel service is NOT THAT great!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8826ca0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbb2814",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "975f8d6d",
   "metadata": {},
   "source": [
    "## module 7 \n",
    "#### chunking (shallow PArsing)\n",
    "break into small meaningful groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8377c2c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('John', 'NNP'),\n",
       " ('found', 'VBD'),\n",
       " ('a', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('coach', 'NN'),\n",
       " ('and', 'CC'),\n",
       " ('a', 'DT'),\n",
       " ('new', 'JJ'),\n",
       " ('bed', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('his', 'PRP$'),\n",
       " ('new', 'JJ'),\n",
       " ('apartment', 'NN')]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "mystring = \"John found a new coach and a new bed in his new apartment.\"\n",
    "output = TextBlob(mystring)\n",
    "output.tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf222552",
   "metadata": {},
   "source": [
    "parse with regex some patterns on pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9852a8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "regex=\"NP:{<DT>?<JJ>*<NN>}\" #1-0, 0+ 1\n",
    "rp = nltk.chunk.RegexpParser(regex)\n",
    "# Regex p Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0ef03a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  John/NNP\n",
      "  found/VBD\n",
      "  (NP a/DT new/JJ coach/NN)\n",
      "  and/CC\n",
      "  (NP a/DT new/JJ bed/NN)\n",
      "  in/IN\n",
      "  his/PRP$\n",
      "  (NP new/JJ apartment/NN))\n"
     ]
    }
   ],
   "source": [
    "output = rp.parse(output.tags)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87e987b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06ad68e",
   "metadata": {},
   "source": [
    "## Chinking\n",
    "removing unwanted word from chunks  \n",
    "remove a chunk from chunk\n",
    "\n",
    "REmove is different than deleting\n",
    "\n",
    "{} , }{\n",
    "    \n",
    "if the mathcin sequence of tokens spans an entire chunk then the whole chunk is removed  \n",
    "    teniendo un chunk, y un chink que coincidan igual, todo se elimina, el chink gana  \n",
    "    if the matching is in the middle it gets removed and left 2 smaller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef06b396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 'DT'),\n",
       " ('little', 'JJ'),\n",
       " ('yellow', 'JJ'),\n",
       " ('dog', 'NN'),\n",
       " ('barked', 'VBD'),\n",
       " ('at', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('cat', 'NN')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string2=\"the little yellow dog barked at the cat.\"\n",
    "output= TextBlob(string2)\n",
    "output.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "872cbe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex2=r\"\"\"NP:\n",
    "{<.*>+}       # chunk everything\n",
    "}<VBD|IN>+{   # chink sequenced of VBD and IN\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50ded0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP the/DT little/JJ yellow/JJ dog/NN)\n",
      "  barked/VBD\n",
      "  at/IN\n",
      "  (NP the/DT cat/NN))\n"
     ]
    }
   ],
   "source": [
    "rp = nltk.chunk.RegexpParser(regex2)\n",
    "output=rp.parse(output.tags)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd91dffa",
   "metadata": {},
   "source": [
    "#  \n",
    "#  \n",
    "#  \n",
    "# Module 8 \n",
    "### PIPELINES\n",
    "\n",
    "Allows to test different modelling training, \n",
    "simpler and cleaner, and callable as argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8da49f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "# import news dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b93c693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that is going to receive pipeline and X, Y\n",
    "def train_test(classifier, X, y):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.25, random_state=48)\n",
    "    classifier.fit(X_train,y_train)\n",
    "    print(\"classifier accuracy is\", classifier.score(X_test,y_test))\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b94cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "trial1 = Pipeline([(\"vectorizer\",TfidfVectorizer()),\n",
    "                  (\"classifier\", MultinomialNB())])\n",
    "train_test(trial1, news.data, news.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1536bdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEcond Pipeline\n",
    "trial2 = Pipeline([('vectorizer',TfidfVectorizer(stop_words=stop_words.words('english'))),\n",
    "                  ('classifier',MultinomialNB())])\n",
    "train_test(trail2,news.data, news.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a07296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#third pipeline\n",
    "trial3 = Pipeline([('vectorizer', TfidfVectorizer(stop_words=stop_words.words('english'))),\n",
    "                  ('classifier', MultinomialNB(alpha=0.05))])\n",
    "train_test(trial3, news.data, news.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896ee8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourth pipeline\n",
    "from sklearn import svm\n",
    "trial4 = Pipeline([('vectorizer',TfidfVectorizer(stop_words=stop_words.words('english'))),\n",
    "                  ('classifier', svm.LinearSVC())])\n",
    "train_test(trial4, news.data, news.target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47549a8",
   "metadata": {},
   "source": [
    "\n",
    "#  \n",
    "#  \n",
    "#  \n",
    "# Module 10  \n",
    "## Word2Vec\n",
    "\n",
    "USed to generate vector representation of words. is a 2layer neuralnet, to process vector words    \n",
    "It is also called word embedding  \n",
    "The vector of each word is the semantic representation that how the word is using the context\n",
    "\n",
    "\n",
    "Words as integers, will affect the training as they cannot give exact context and semantics, it will consider surrounding words as similar.  \n",
    "adding dimension for semantics will improve the relations\n",
    "\n",
    "therefore, another similar word will have a similar vector, then it will be better interpreted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5e6e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize\n",
    "text = \"This is our first sentence. This is the second one, and one more.\"\n",
    "\n",
    "sentences = sent_tokenize(text)\n",
    "token = [word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53fcf607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "model = Word2Vec(token, min_count=1, vector_size=50)\n",
    "# size is the number of dimension of the vector. bigger size require more trianing fata but leads to better accuracy.\n",
    "# min_count is minimum number of ocurrences of a word to be considered in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18c27b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=12, vector_size=50, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2fa0098a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " '.',\n",
       " 'is',\n",
       " 'This',\n",
       " 'more',\n",
       " 'and',\n",
       " ',',\n",
       " 'second',\n",
       " 'the',\n",
       " 'sentence',\n",
       " 'first',\n",
       " 'our']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = list(model.wv.index_to_key)\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cd77cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00805479  0.00869582  0.01991692 -0.00894846 -0.00277883 -0.01463625\n",
      " -0.01939779 -0.01816251 -0.00204573 -0.01300801  0.00970052 -0.01232941\n",
      "  0.00503892  0.00147904 -0.00678505 -0.00195866  0.01996044  0.01829378\n",
      " -0.00892464  0.01816805 -0.01128476  0.01186315 -0.00619512  0.00686426\n",
      "  0.00603512  0.01380244 -0.00474829  0.017552    0.01518052 -0.01909739\n",
      " -0.01601818 -0.01527747  0.00584716 -0.00559006 -0.01386056 -0.01625831\n",
      "  0.01662018  0.00398141 -0.01865808 -0.00958648  0.00627417 -0.00942745\n",
      "  0.01056284 -0.00846781  0.00528417 -0.01609314  0.01242113  0.00963884\n",
      "  0.00157456  0.00602756]\n"
     ]
    }
   ],
   "source": [
    "print(model.wv['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3adf6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec<vocab=12, vector_size=50, alpha=0.025>\n"
     ]
    }
   ],
   "source": [
    "model.save('wvmodel.bin')\n",
    "model_load = Word2Vec.load('wvmodel.bin')\n",
    "print(model_load)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83568d30",
   "metadata": {},
   "source": [
    "### Contextualized word embedding\n",
    "static word embaddings, provide an exact meaning to words. But depending on the context this may change, therefore, it is a problem on word embeddings [Si se hace el embedding para una palabra \"rain\" y la detecta como el agua que cae, y despues aparece como verbo, sera interpretada como el agua y no como verbo]  \n",
    "\n",
    "So, the contextualized word embedding came into picture.\n",
    "They create a vector for each word conditioned on tis context\n",
    "\n",
    "Representatin for each word is a function of the entire input sentence (function: se crea a partir de las demas)\n",
    "\n",
    "Lista de Dynamic LMs / Contextualized Word Embeddings (CWE):\n",
    "BERT  \n",
    "ELMO  \n",
    "GPT  \n",
    "Transformers  \n",
    "Cove, ELMFiT, CoVe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e64f24",
   "metadata": {},
   "source": [
    "### ELMO\n",
    "Embedding Language Model\n",
    "pretrained models for downsream tasks, \n",
    "LSTM, considering surrounding words\n",
    "\n",
    "### BERT\n",
    "Bidirectional Encoder Representation from TRansformer, milestone after elmo\n",
    "uses pretrained transformers language model.\n",
    "TRained by masking 15% of the words, task is to predict those words.\n",
    "800M words from BookCorpus, and 2.500M wiki\n",
    "can be fined tuned with our own data\n",
    "\n",
    "\n",
    "\n",
    "###  GPT-2\n",
    "Transformer-based model.\n",
    "for any downstream task\n",
    "it uses more parameters (1.452 M parameters)\n",
    "trained with book corpus (800M words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d15241",
   "metadata": {},
   "source": [
    "## Word2Vec uses cases\n",
    "Analyze: Surveys, verbatim comments in forums\n",
    "Recommendation systems\n",
    "\n",
    "it finds complex relationshups between the response being reviewed and the specific conett within which the response was made.\n",
    "\n",
    "\n",
    "\n",
    "These models can work not only for text, but also on other areas, such as recommendation systems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cf4ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  \n",
    "#  \n",
    "#  \n",
    "#  \n",
    "#  \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
