{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6c3b9c28",
   "metadata": {},
   "source": [
    "Use transformers? GPT api,  \n",
    "How to process data  \n",
    "\n",
    "divide in sentences, lowercase, firstword only (if not detected as NER)  \n",
    "then all to tokens\n",
    "\n",
    "\n",
    "**Preprocessing Steps for identification:**  \n",
    "- <u>Lowercasing:</u>  \n",
    "Convert the text to lowercase to ensure consistency and avoid duplicating words with different cases. For example, \"Movie\" and \"movie\" should be treated as the same word.\n",
    "  \n",
    "- <u>Tokenization:  </u>  \n",
    "Split the text into individual words or tokens. Tokenization helps to break down the text into meaningful units for further processing. You can use libraries like NLTK or spaCy for tokenization.\n",
    "  \n",
    "- <u>Removal of Special Characters and Punctuation:</u>  \n",
    "Remove special characters, punctuation marks, and symbols from the text. These elements generally do not contribute significantly to the semantic meaning and can introduce noise in the analysis.\n",
    "  \n",
    "- <u>Removal of Stopwords:</u>    \n",
    "Eliminate common words, known as stopwords (e.g., \"the,\" \"is,\" \"and\"), as they typically do not carry significant information for identification or similarity tasks. NLTK provides a list of stopwords for various languages.\n",
    "  \n",
    "- <u>Lemmatization or Stemming:</u>  \n",
    "Reduce words to their base or root form to unify semantically similar words. This step helps to handle variations such as singular/plural forms and verb tenses. NLTK provides modules for lemmatization and stemming.\n",
    "  \n",
    "- <u>Removal of Numeric Tokens:</u>  \n",
    "Exclude numeric tokens or words from the preprocessing steps, as they may not contribute much to the identification or similarity analysis unless specific numerical information is essential in your task.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e6ee367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivan/opt/anaconda3/envs/sem2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-06-26 20:20:15.508618: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b061c5b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('This', 'PRON'), ('is', 'AUX'), ('a', 'DET'), ('sentence', 'NOUN'), ('.', 'PUNCT')]\n"
     ]
    }
   ],
   "source": [
    "# python -m spacy download en_core_web_sm\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "# import en_core_web_sm\n",
    "# nlp = en_core_web_sm.load()\n",
    "doc = nlp(\"This is a sentence.\")\n",
    "print([(w.text, w.pos_) for w in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f90961c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n"
     ]
    }
   ],
   "source": [
    "df_raw=pd.read_csv('Movie-2023-06-15.csv')\n",
    "print(len(df_raw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7539e4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'imdb_id', 'name', 'year', 'rating', 'certificate', 'duration',\n",
      "       'genre', 'votes', 'gross_income', 'director_id', 'director_name',\n",
      "       'starts_id', 'starts_name', 'description', 'url', 'payload', 'status',\n",
      "       'attempt', 'created', 'updated'],\n",
      "      dtype='object')\n",
      "89\n",
      "Index(['id', 'imdb_id', 'name', 'year', 'starts_name', 'description'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>starts_name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c8de01ac-04c2-444a-9d9b-26cb213a9b2f</td>\n",
       "      <td>tt0241527</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone</td>\n",
       "      <td>2001</td>\n",
       "      <td>Richard Harris,Maggie Smith,Robbie Coltrane,Sa...</td>\n",
       "      <td>An orphaned boy enrolls in a school of wizardr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d76d12d5-caa4-4101-93da-52012300efa6</td>\n",
       "      <td>tt0117060</td>\n",
       "      <td>Mission: Impossible</td>\n",
       "      <td>1996</td>\n",
       "      <td>Tom Cruise,Jon Voight,Emmanuelle Bart,Henry Cz...</td>\n",
       "      <td>An American agent, under false suspicion of di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b6e07841-25c9-49b8-b563-ef3007753017</td>\n",
       "      <td>tt0068646</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>Marlon Brando,Al Pacino,James Caan,Richard S. ...</td>\n",
       "      <td>Don Vito Corleone, head of a mafia family, dec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9b175434-f80c-4d7a-a98d-e0551ba61af3</td>\n",
       "      <td>tt1201607</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 2</td>\n",
       "      <td>2011</td>\n",
       "      <td>Ralph Fiennes,Michael Gambon,Alan Rickman,Dani...</td>\n",
       "      <td>Harry, Ron, and Hermione search for Voldemort'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ff11b3f0-c8cb-426b-a51b-0790bedbff8b</td>\n",
       "      <td>tt0090605</td>\n",
       "      <td>Aliens</td>\n",
       "      <td>1986</td>\n",
       "      <td>Sigourney Weaver,Carrie Henn,Michael Biehn,Pau...</td>\n",
       "      <td>Decades after surviving the Nostromo incident,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     id    imdb_id  \\\n",
       "0  c8de01ac-04c2-444a-9d9b-26cb213a9b2f  tt0241527   \n",
       "1  d76d12d5-caa4-4101-93da-52012300efa6  tt0117060   \n",
       "2  b6e07841-25c9-49b8-b563-ef3007753017  tt0068646   \n",
       "3  9b175434-f80c-4d7a-a98d-e0551ba61af3  tt1201607   \n",
       "4  ff11b3f0-c8cb-426b-a51b-0790bedbff8b  tt0090605   \n",
       "\n",
       "                                           name  year  \\\n",
       "0         Harry Potter and the Sorcerer's Stone  2001   \n",
       "1                           Mission: Impossible  1996   \n",
       "2                                 The Godfather  1972   \n",
       "3  Harry Potter and the Deathly Hallows: Part 2  2011   \n",
       "4                                        Aliens  1986   \n",
       "\n",
       "                                         starts_name  \\\n",
       "0  Richard Harris,Maggie Smith,Robbie Coltrane,Sa...   \n",
       "1  Tom Cruise,Jon Voight,Emmanuelle Bart,Henry Cz...   \n",
       "2  Marlon Brando,Al Pacino,James Caan,Richard S. ...   \n",
       "3  Ralph Fiennes,Michael Gambon,Alan Rickman,Dani...   \n",
       "4  Sigourney Weaver,Carrie Henn,Michael Biehn,Pau...   \n",
       "\n",
       "                                         description  \n",
       "0  An orphaned boy enrolls in a school of wizardr...  \n",
       "1  An American agent, under false suspicion of di...  \n",
       "2  Don Vito Corleone, head of a mafia family, dec...  \n",
       "3  Harry, Ron, and Hermione search for Voldemort'...  \n",
       "4  Decades after surviving the Nostromo incident,...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_raw.columns)\n",
    "\n",
    "df=df_raw[['id', 'imdb_id', 'name', 'year','starts_name', 'description']]\n",
    "print(len(df))\n",
    "print(df.columns)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da097ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harry Potter and the Sorcerer's Stone\n"
     ]
    }
   ],
   "source": [
    "print(df.loc[0,'name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33514c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_raw_hp2 = \"In this movie Ginny open it with a diary, and there is a big snake. Emma Watson as hermione, ron help Harry to defend from Voldemort, also Harry can talk to it in the girls bathroom. \"\n",
    "summary_raw_hp8 = \"In this movie Harry have destroyed most Horcruxes, and he Hermione and Ron Have to fight Voldemort. There is a huge battle of wizards in the castle of Hogwarts. Weasly die in the fight, but one twin lose his ear. \"\n",
    "summary_raw_gf='a gangster try to get into a family business,Corleone with the italians. they are in the mafia family, the head of the Corleone Mafia family '\n",
    "summary_raw_mi=\" the IMF agent Ethan Hunt gets bretrayed and have to steal the noc list.\"\n",
    "dataset_raw = df['description'].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734acd2c",
   "metadata": {},
   "source": [
    "# NLTK approach1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "640dad21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopword = stopwords.words('english')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.replace('\\n','. ')#.replace('','').replace('','').replace('','')\n",
    "#     text = text.replace(',',' ').replace('!','').replace('?','')\n",
    "    return text\n",
    "\n",
    "def remove_punct(text, lower=False):\n",
    "    if(type(text)==str):\n",
    "        text = text.replace('\\n','. ')#.replace('','').replace('','').replace('','')\n",
    "        text = text.replace(',',' ').replace('!','').replace('?',' ')\n",
    "        text = text.replace('.',' ').replace('#','').replace('$',' ')\n",
    "        text = text.replace('^',' ').replace('&','and').replace(';',' ')\n",
    "        text = text.replace('  ',' ')\n",
    "        return text\n",
    "    elif(type(text)==list):\n",
    "        _words=[]\n",
    "        for w in text:\n",
    "            if w.isalnum():\n",
    "                _words.append(w if not lower else w.lower())\n",
    "#         print('remove_punct',len(_words))\n",
    "        return _words\n",
    "\n",
    "def get_sentences(text):\n",
    "    return sent_tokenize(text)\n",
    "\n",
    "def get_tokens(text):\n",
    "    words =[]\n",
    "    for w in word_tokenize(text):\n",
    "        if w.isalnum():\n",
    "            words.append(w)\n",
    "    return words\n",
    "    \n",
    "\n",
    "def remove_stopwords(words):\n",
    "    just_words=[]\n",
    "    for word in words:\n",
    "        if word.lower() not in stopword:\n",
    "            just_words.append(word)\n",
    "#     print('just_words',len(just_words))\n",
    "    return just_words\n",
    "    \n",
    "    \n",
    "def lemmatize(text):\n",
    "    record_lemmatized = [lemmatizer.lemmatize(token) for token in text]\n",
    "    return record_lemmatized\n",
    "    \n",
    "    \n",
    "def list_to_string(ls):\n",
    "    return \" \".join(ls)\n",
    "    \n",
    "# clean words: boooook\n",
    "# Remove non stop words of 2 letters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Cleaning approach 1:\n",
    "    # tokenize everything, remove stop words, lower all, remove punctutation\n",
    "\n",
    "# set tokens each description\n",
    "dataset_tokens= [ get_tokens(x) for x in dataset_raw] \n",
    "\n",
    "# remove stopwords\n",
    "dataset_nostopwords= [remove_stopwords(x) for x in dataset_tokens]\n",
    "\n",
    "# remove punctuation\n",
    "dataset_main_words= [remove_punct(x, lower=False) for x in dataset_nostopwords ]\n",
    "\n",
    "# Lower all\n",
    "# dataset_main_words_lower=[x.lower() for x in dataset_main_words]\n",
    "\n",
    "# Lemmatize words\n",
    "# record_lemmatized = [lemmatizer.lemmatize(token) for token in dataset_main_words]\n",
    "\n",
    "\n",
    "# Back to string\n",
    "dataset_clean_text = [ list_to_string(x) for x in dataset_main_words]\n",
    "\n",
    "def preprocess_text_ap1(x):\n",
    "       # tokenize everything, remove stop words, lower all, remove punctutation\n",
    "    # set tokens each description\n",
    "    dataset_tokens= get_tokens(x)\n",
    "    # remove stopwords\n",
    "    dataset_nostopwords= remove_stopwords(dataset_tokens)\n",
    "    # remove punctuation\n",
    "    dataset_main_words= remove_punct(dataset_nostopwords, lower=False)\n",
    "    # Lower all\n",
    "    # dataset_main_words_lower=[x.lower() for x in dataset_main_words]\n",
    "    # Back to string\n",
    "    dataset_clean_text =  list_to_string(dataset_main_words)\n",
    "    return dataset_clean_text"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4d06532d",
   "metadata": {},
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace('\\n','. ')#.replace('','').replace('','').replace('','')\n",
    "#     text = text.replace(',',' ').replace('!','').replace('?','')\n",
    "    return text\n",
    "\n",
    "def remove_punct(text, lower=False):\n",
    "    if(type(text)==str):\n",
    "        text = text.replace('\\n','. ')#.replace('','').replace('','').replace('','')\n",
    "        text = text.replace(',',' ').replace('!','').replace('?',' ')\n",
    "        text = text.replace('.',' ').replace('#','').replace('$',' ')\n",
    "        text = text.replace('^',' ').replace('&','and').replace(';',' ')\n",
    "        text = text.replace('  ',' ')\n",
    "        return text\n",
    "    elif(type(text)==list):\n",
    "        _words=[]\n",
    "        for w in text:\n",
    "            if w.isalnum():\n",
    "                _words.append(w if not lower else w.lower())\n",
    "#         print('remove_punct',len(_words))\n",
    "        return _words\n",
    "\n",
    "def get_sentences(text):\n",
    "    return sent_tokenize(text)\n",
    "\n",
    "def get_tokens(text):\n",
    "    words =[]\n",
    "    for w in word_tokenize(text):\n",
    "        if w.isalnum():\n",
    "            words.append(w)\n",
    "    return words\n",
    "    \n",
    "\n",
    "def remove_stopwords(words):\n",
    "    just_words=[]\n",
    "    for word in words:\n",
    "        if word.lower() not in stopword:\n",
    "            just_words.append(word)\n",
    "#     print('just_words',len(just_words))\n",
    "    return just_words\n",
    "    \n",
    "    \n",
    "def lemmatize(text):\n",
    "    record_lemmatized = [lemmatizer.lemmatize(token) for token in text]\n",
    "    return record_lemmatized\n",
    "    \n",
    "    \n",
    "def list_to_string(ls):\n",
    "    return \" \".join(ls)\n",
    "    \n",
    "# clean words: boooook\n",
    "# Remove non stop words of 2 letters\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e3b5f9a7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ae2651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "e7704ac5",
   "metadata": {},
   "source": [
    "# Cleaning approach 1:\n",
    "    # tokenize everything, remove stop words, lower all, remove punctutation\n",
    "\n",
    "# set tokens each description\n",
    "dataset_tokens= [ get_tokens(x) for x in dataset_raw] \n",
    "\n",
    "# remove stopwords\n",
    "dataset_nostopwords= [remove_stopwords(x) for x in dataset_tokens]\n",
    "\n",
    "# remove punctuation\n",
    "dataset_main_words= [remove_punct(x, lower=False) for x in dataset_nostopwords ]\n",
    "\n",
    "# Lower all\n",
    "# dataset_main_words_lower=[x.lower() for x in dataset_main_words]\n",
    "\n",
    "# Lemmatize words\n",
    "# record_lemmatized = [lemmatizer.lemmatize(token) for token in dataset_main_words]\n",
    "\n",
    "\n",
    "# Back to string\n",
    "dataset_clean_text = [ list_to_string(x) for x in dataset_main_words]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe77a0fd",
   "metadata": {},
   "source": [
    "def preprocess_text_ap1(x):\n",
    "       # tokenize everything, remove stop words, lower all, remove punctutation\n",
    "    # set tokens each description\n",
    "    dataset_tokens= get_tokens(x)\n",
    "    # remove stopwords\n",
    "    dataset_nostopwords= remove_stopwords(dataset_tokens)\n",
    "    # remove punctuation\n",
    "    dataset_main_words= remove_punct(dataset_nostopwords, lower=False)\n",
    "    # Lower all\n",
    "    # dataset_main_words_lower=[x.lower() for x in dataset_main_words]\n",
    "    # Back to string\n",
    "    dataset_clean_text =  list_to_string(dataset_main_words)\n",
    "    return dataset_clean_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8c5a1a",
   "metadata": {},
   "source": [
    "# SPACY\n",
    "\n",
    "Do not lower all words, lower, Only, after found is not a NER Name person or company or movie:  \n",
    "i.e. Ethan Hunt - > hunt is now vverb, not last name  \n",
    "Lily Potter -> is now lily (flower) potter (proffesion)  \n",
    "Max Power -> all power"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d1a6d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datasets\n",
    "## Ment to do once\n",
    "\n",
    "# dataset=dataset_raw\n",
    "# datasets=[\" \".join(get_tokens(clean_text(x))) for x in dataset_raw]\n",
    "\n",
    "dataset_clean_text=[preprocess_text_ap1(x) for x in dataset_clean_text]\n",
    "\n",
    "datasets=dataset_clean_text\n",
    "dataset_docs = [nlp(record) for record in datasets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "685d39e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets= dataset_docs.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e89db29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tMysUmmary:\n",
      " In this movie Harry have destroyed most Horcruxes, and he Hermione and Ron Have to fight Voldemort. There is a huge battle of wizards in the castle of Hogwarts. Weasly die in the fight, but one twin lose his ear. ,\n",
      "\tSummary NLP:\n",
      "movie Harry destroyed Horcruxes Hermione Ron fight Voldemort huge battle wizards castle Hogwarts Weasly die fight one twin lose ear\n",
      "Similar:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Harry Ron Hermione search Voldemort remaining Horcruxes effort destroy Dark Lord final battle rages Hogwarts burying Dobby garden Shell cottage Harry Potter Daniel Radcliffe Warwick Davis help get Lestrange vault Gringotts Voldemort Horcruxes exchange Godric Gryffindor Ollivander John Hurt Wandmaker warns Harry wo stand Voldemort Ralph Fiennes Elder Wand arrived Gringotts Hermione Emma Watson disguised Bellatrix Helena Bonham Carter using Polyjuice Potion Ron Rupert Grint disguised random wizard Harry Griphook go Invisibility Cloak help Imperius curse manage get carts take vaults cover blown Gringotts security attacks manage get Lestrange vault find Horcrux Helga Hufflepuff Cup Griphook betrays flees sword yelling"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_raw=summary_raw_hp8 #->hp4 -> cambio\n",
    "# summary_raw=summary_raw_gf #->Han Solo Jabba Hutt Rebels\n",
    "# summary_raw=summary_raw_mi #->widow Emily French Norma Varden\n",
    "# summary=\" \".join(get_tokens(preprocess_text_ap1(summary_raw)))\n",
    "summary=(preprocess_text_ap1(summary_raw))\n",
    "\n",
    "\n",
    "summary_doc = nlp(summary)\n",
    "\n",
    "similarity_scores = [summary_doc.similarity(doc) for doc in dataset_docs]\n",
    "\n",
    "\n",
    "most_similar_index = similarity_scores.index(max(similarity_scores))\n",
    "most_similar_record = datasets[most_similar_index]\n",
    "\n",
    "# print(\"MySummary:\",summary_raw,'\\nSimilar:')\n",
    "print(f\"\\tMysUmmary:\\n {summary_raw},\\n\\tSummary NLP:\\n{summary}\\nSimilar:\\n\")\n",
    "\n",
    "most_similar_record[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e19c4055",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>starts_name</th>\n",
       "      <th>description</th>\n",
       "      <th>description_nlp</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9b175434-f80c-4d7a-a98d-e0551ba61af3</td>\n",
       "      <td>tt1201607</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 2</td>\n",
       "      <td>2011</td>\n",
       "      <td>Ralph Fiennes,Michael Gambon,Alan Rickman,Dani...</td>\n",
       "      <td>Harry, Ron, and Hermione search for Voldemort'...</td>\n",
       "      <td>(Harry, Ron, Hermione, search, Voldemort, rema...</td>\n",
       "      <td>0.816946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fa5f656d-54b3-4095-bf77-9a8c39443b3a</td>\n",
       "      <td>tt0167260</td>\n",
       "      <td>The Lord of the Rings: The Return of the King</td>\n",
       "      <td>2003</td>\n",
       "      <td>Noel Appleby,Ali Astin,Sean Astin,David Aston,...</td>\n",
       "      <td>Gandalf and Aragorn lead the World of Men agai...</td>\n",
       "      <td>(Gandalf, Aragorn, lead, World, Men, Sauron, a...</td>\n",
       "      <td>0.771519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>19ebeaef-021e-4e3e-9dc7-4d4d319d2fff</td>\n",
       "      <td>tt0167261</td>\n",
       "      <td>The Lord of the Rings: The Two Towers</td>\n",
       "      <td>2002</td>\n",
       "      <td>Bruce Allpress,Sean Astin,John Bach,Sala Baker...</td>\n",
       "      <td>While Frodo and Sam edge closer to Mordor with...</td>\n",
       "      <td>(Frodo, Sam, edge, closer, Mordor, help, shift...</td>\n",
       "      <td>0.765762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c8de01ac-04c2-444a-9d9b-26cb213a9b2f</td>\n",
       "      <td>tt0241527</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone</td>\n",
       "      <td>2001</td>\n",
       "      <td>Richard Harris,Maggie Smith,Robbie Coltrane,Sa...</td>\n",
       "      <td>An orphaned boy enrolls in a school of wizardr...</td>\n",
       "      <td>(orphaned, boy, enrolls, school, wizardry, lea...</td>\n",
       "      <td>0.764040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>911331de-14f6-43d5-a221-c0b821e4c8c7</td>\n",
       "      <td>tt0120737</td>\n",
       "      <td>The Lord of the Rings: The Fellowship of the Ring</td>\n",
       "      <td>2001</td>\n",
       "      <td>Alan Howard,Noel Appleby,Sean Astin,Sala Baker...</td>\n",
       "      <td>A meek Hobbit from the Shire and eight compani...</td>\n",
       "      <td>(meek, Hobbit, Shire, eight, companions, set, ...</td>\n",
       "      <td>0.732214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id    imdb_id  \\\n",
       "3   9b175434-f80c-4d7a-a98d-e0551ba61af3  tt1201607   \n",
       "7   fa5f656d-54b3-4095-bf77-9a8c39443b3a  tt0167260   \n",
       "77  19ebeaef-021e-4e3e-9dc7-4d4d319d2fff  tt0167261   \n",
       "0   c8de01ac-04c2-444a-9d9b-26cb213a9b2f  tt0241527   \n",
       "41  911331de-14f6-43d5-a221-c0b821e4c8c7  tt0120737   \n",
       "\n",
       "                                                 name  year  \\\n",
       "3        Harry Potter and the Deathly Hallows: Part 2  2011   \n",
       "7       The Lord of the Rings: The Return of the King  2003   \n",
       "77              The Lord of the Rings: The Two Towers  2002   \n",
       "0               Harry Potter and the Sorcerer's Stone  2001   \n",
       "41  The Lord of the Rings: The Fellowship of the Ring  2001   \n",
       "\n",
       "                                          starts_name  \\\n",
       "3   Ralph Fiennes,Michael Gambon,Alan Rickman,Dani...   \n",
       "7   Noel Appleby,Ali Astin,Sean Astin,David Aston,...   \n",
       "77  Bruce Allpress,Sean Astin,John Bach,Sala Baker...   \n",
       "0   Richard Harris,Maggie Smith,Robbie Coltrane,Sa...   \n",
       "41  Alan Howard,Noel Appleby,Sean Astin,Sala Baker...   \n",
       "\n",
       "                                          description  \\\n",
       "3   Harry, Ron, and Hermione search for Voldemort'...   \n",
       "7   Gandalf and Aragorn lead the World of Men agai...   \n",
       "77  While Frodo and Sam edge closer to Mordor with...   \n",
       "0   An orphaned boy enrolls in a school of wizardr...   \n",
       "41  A meek Hobbit from the Shire and eight compani...   \n",
       "\n",
       "                                      description_nlp  similarity  \n",
       "3   (Harry, Ron, Hermione, search, Voldemort, rema...    0.816946  \n",
       "7   (Gandalf, Aragorn, lead, World, Men, Sauron, a...    0.771519  \n",
       "77  (Frodo, Sam, edge, closer, Mordor, help, shift...    0.765762  \n",
       "0   (orphaned, boy, enrolls, school, wizardry, lea...    0.764040  \n",
       "41  (meek, Hobbit, Shire, eight, companions, set, ...    0.732214  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# datasets_results_df = pd.DataFrame(columns=['title','description','similarity'], data=[range(0,len(similarity_scores)),datasets,similarity_scores])\n",
    "# datasets_results_df = pd.DataFrame(columns=['title'], data=df['title'])\n",
    "datasets_results_df=df.copy()\n",
    "datasets_results_df['description_nlp']=datasets\n",
    "datasets_results_df['similarity']=similarity_scores\n",
    "datasets_results_df.sort_values(by='similarity', inplace=True, ascending=False)\n",
    "datasets_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a4bd62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42fb007b",
   "metadata": {},
   "source": [
    "# Probando el accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b25e7ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_jw = pd.read_csv('Movie-2023-06-15_justwatch.csv')\n",
    "del df_jw['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1869758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_movie(_synopsis):\n",
    "    summary_raw=_synopsis \n",
    "    summary=(preprocess_text_ap1(summary_raw))\n",
    "    summary_doc = nlp(summary)\n",
    "    similarity_scores = [summary_doc.similarity(doc) for doc in dataset_docs]\n",
    "    most_similar_index = similarity_scores.index(max(similarity_scores))\n",
    "  \n",
    "    df_match = df.iloc[most_similar_index]#[df['']]\n",
    "    # THe best this, is to find the movie in the dataset, return title, year and link\n",
    "    return df_match #most_similar_record.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be9eeeea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>description_clean</th>\n",
       "      <th>name</th>\n",
       "      <th>year</th>\n",
       "      <th>starts_name</th>\n",
       "      <th>description</th>\n",
       "      <th>justwatch_name</th>\n",
       "      <th>justwatch_snps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c8de01ac-04c2-444a-9d9b-26cb213a9b2f</td>\n",
       "      <td>tt0241527</td>\n",
       "      <td>orphaned boy enrolls school wizardry learns tr...</td>\n",
       "      <td>Harry Potter and the Sorcerer's Stone</td>\n",
       "      <td>2001</td>\n",
       "      <td>Richard Harris,Maggie Smith,Robbie Coltrane,Sa...</td>\n",
       "      <td>An orphaned boy enrolls in a school of wizardr...</td>\n",
       "      <td>harry-potter-and-the-philosophers-stone</td>\n",
       "      <td>Harry Potter has lived under the stairs at his...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d76d12d5-caa4-4101-93da-52012300efa6</td>\n",
       "      <td>tt0117060</td>\n",
       "      <td>American agent false suspicion disloyalty must...</td>\n",
       "      <td>Mission: Impossible</td>\n",
       "      <td>1996</td>\n",
       "      <td>Tom Cruise,Jon Voight,Emmanuelle Bart,Henry Cz...</td>\n",
       "      <td>An American agent, under false suspicion of di...</td>\n",
       "      <td>mission-impossible</td>\n",
       "      <td>When Ethan Hunt, the leader of a crack espiona...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b6e07841-25c9-49b8-b563-ef3007753017</td>\n",
       "      <td>tt0068646</td>\n",
       "      <td>Vito Corleone head mafia family decides hand e...</td>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>Marlon Brando,Al Pacino,James Caan,Richard S. ...</td>\n",
       "      <td>Don Vito Corleone, head of a mafia family, dec...</td>\n",
       "      <td>the-godfather</td>\n",
       "      <td>Spanning the years 1945 to 1955, a chronicle o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9b175434-f80c-4d7a-a98d-e0551ba61af3</td>\n",
       "      <td>tt1201607</td>\n",
       "      <td>Harry Ron Hermione search Voldemort remaining ...</td>\n",
       "      <td>Harry Potter and the Deathly Hallows: Part 2</td>\n",
       "      <td>2011</td>\n",
       "      <td>Ralph Fiennes,Michael Gambon,Alan Rickman,Dani...</td>\n",
       "      <td>Harry, Ron, and Hermione search for Voldemort'...</td>\n",
       "      <td>harry-potter-and-the-deathly-hallows-part-2</td>\n",
       "      <td>Harry, Ron and Hermione continue their quest t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ff11b3f0-c8cb-426b-a51b-0790bedbff8b</td>\n",
       "      <td>tt0090605</td>\n",
       "      <td>Decades surviving Nostromo incident Ellen Ripl...</td>\n",
       "      <td>Aliens</td>\n",
       "      <td>1986</td>\n",
       "      <td>Sigourney Weaver,Carrie Henn,Michael Biehn,Pau...</td>\n",
       "      <td>Decades after surviving the Nostromo incident,...</td>\n",
       "      <td>aliens</td>\n",
       "      <td>Two young boys discuss their favorite movies a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0cf96760-1af3-463a-9be3-782356685573</td>\n",
       "      <td>tt0056172</td>\n",
       "      <td>story Lawrence English officer successfully un...</td>\n",
       "      <td>Lawrence of Arabia</td>\n",
       "      <td>1962</td>\n",
       "      <td>Peter O'Toole,Alec Guinness,Anthony Quinn,Jack...</td>\n",
       "      <td>The story of T.E. Lawrence, the English office...</td>\n",
       "      <td>lawrence-of-arabia</td>\n",
       "      <td>The story of British officer T.E. Lawrence's m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>04b3a719-1b70-462a-b7c5-3fae85109e4b</td>\n",
       "      <td>tt0050825</td>\n",
       "      <td>refusing attack enemy position general accuses...</td>\n",
       "      <td>Paths of Glory</td>\n",
       "      <td>1957</td>\n",
       "      <td>Kirk Douglas,Ralph Meeker,Adolphe Menjou,Georg...</td>\n",
       "      <td>After refusing to attack an enemy position, a ...</td>\n",
       "      <td>paths-of-glory</td>\n",
       "      <td>A commanding officer defends three scapegoats ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>02311676-0ca3-4149-a40e-4346f0b910da</td>\n",
       "      <td>tt0364569</td>\n",
       "      <td>kidnapped imprisoned fifteen years Oh released...</td>\n",
       "      <td>Oldboy</td>\n",
       "      <td>2003</td>\n",
       "      <td>Choi Min-sik,Yoo Ji-tae,Kang Hye-jeong,Kim Bye...</td>\n",
       "      <td>After being kidnapped and imprisoned for fifte...</td>\n",
       "      <td>oldboy</td>\n",
       "      <td>An everyday man has only three and a half days...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>01e562bc-9e59-4019-806d-97deb6a82f2b</td>\n",
       "      <td>tt7286456</td>\n",
       "      <td>rise Arthur Fleck aspiring comedian pariah Got...</td>\n",
       "      <td>Joker</td>\n",
       "      <td>2019</td>\n",
       "      <td>Joaquin Phoenix,Robert De Niro,Zazie Beetz,Fra...</td>\n",
       "      <td>The rise of Arthur Fleck, from aspiring stand-...</td>\n",
       "      <td>joker</td>\n",
       "      <td>Mannar Mannan, an ordinary villager, decides t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>49cbfde7-589f-4f24-b052-5ef49c2c6cf7</td>\n",
       "      <td>tt0317248</td>\n",
       "      <td>slums Rio two kids paths diverge one struggles...</td>\n",
       "      <td>City of God</td>\n",
       "      <td>2002</td>\n",
       "      <td>Alexandre Rodrigues,Leandro Firmino,Phellipe H...</td>\n",
       "      <td>In the slums of Rio, two kids' paths diverge a...</td>\n",
       "      <td>city-of-god</td>\n",
       "      <td>In the slums of Rio, two kids' paths diverge a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      id    imdb_id  \\\n",
       "0   c8de01ac-04c2-444a-9d9b-26cb213a9b2f  tt0241527   \n",
       "1   d76d12d5-caa4-4101-93da-52012300efa6  tt0117060   \n",
       "2   b6e07841-25c9-49b8-b563-ef3007753017  tt0068646   \n",
       "3   9b175434-f80c-4d7a-a98d-e0551ba61af3  tt1201607   \n",
       "4   ff11b3f0-c8cb-426b-a51b-0790bedbff8b  tt0090605   \n",
       "..                                   ...        ...   \n",
       "84  0cf96760-1af3-463a-9be3-782356685573  tt0056172   \n",
       "85  04b3a719-1b70-462a-b7c5-3fae85109e4b  tt0050825   \n",
       "86  02311676-0ca3-4149-a40e-4346f0b910da  tt0364569   \n",
       "87  01e562bc-9e59-4019-806d-97deb6a82f2b  tt7286456   \n",
       "88  49cbfde7-589f-4f24-b052-5ef49c2c6cf7  tt0317248   \n",
       "\n",
       "                                    description_clean  \\\n",
       "0   orphaned boy enrolls school wizardry learns tr...   \n",
       "1   American agent false suspicion disloyalty must...   \n",
       "2   Vito Corleone head mafia family decides hand e...   \n",
       "3   Harry Ron Hermione search Voldemort remaining ...   \n",
       "4   Decades surviving Nostromo incident Ellen Ripl...   \n",
       "..                                                ...   \n",
       "84  story Lawrence English officer successfully un...   \n",
       "85  refusing attack enemy position general accuses...   \n",
       "86  kidnapped imprisoned fifteen years Oh released...   \n",
       "87  rise Arthur Fleck aspiring comedian pariah Got...   \n",
       "88  slums Rio two kids paths diverge one struggles...   \n",
       "\n",
       "                                            name  year  \\\n",
       "0          Harry Potter and the Sorcerer's Stone  2001   \n",
       "1                            Mission: Impossible  1996   \n",
       "2                                  The Godfather  1972   \n",
       "3   Harry Potter and the Deathly Hallows: Part 2  2011   \n",
       "4                                         Aliens  1986   \n",
       "..                                           ...   ...   \n",
       "84                            Lawrence of Arabia  1962   \n",
       "85                                Paths of Glory  1957   \n",
       "86                                        Oldboy  2003   \n",
       "87                                         Joker  2019   \n",
       "88                                   City of God  2002   \n",
       "\n",
       "                                          starts_name  \\\n",
       "0   Richard Harris,Maggie Smith,Robbie Coltrane,Sa...   \n",
       "1   Tom Cruise,Jon Voight,Emmanuelle Bart,Henry Cz...   \n",
       "2   Marlon Brando,Al Pacino,James Caan,Richard S. ...   \n",
       "3   Ralph Fiennes,Michael Gambon,Alan Rickman,Dani...   \n",
       "4   Sigourney Weaver,Carrie Henn,Michael Biehn,Pau...   \n",
       "..                                                ...   \n",
       "84  Peter O'Toole,Alec Guinness,Anthony Quinn,Jack...   \n",
       "85  Kirk Douglas,Ralph Meeker,Adolphe Menjou,Georg...   \n",
       "86  Choi Min-sik,Yoo Ji-tae,Kang Hye-jeong,Kim Bye...   \n",
       "87  Joaquin Phoenix,Robert De Niro,Zazie Beetz,Fra...   \n",
       "88  Alexandre Rodrigues,Leandro Firmino,Phellipe H...   \n",
       "\n",
       "                                          description  \\\n",
       "0   An orphaned boy enrolls in a school of wizardr...   \n",
       "1   An American agent, under false suspicion of di...   \n",
       "2   Don Vito Corleone, head of a mafia family, dec...   \n",
       "3   Harry, Ron, and Hermione search for Voldemort'...   \n",
       "4   Decades after surviving the Nostromo incident,...   \n",
       "..                                                ...   \n",
       "84  The story of T.E. Lawrence, the English office...   \n",
       "85  After refusing to attack an enemy position, a ...   \n",
       "86  After being kidnapped and imprisoned for fifte...   \n",
       "87  The rise of Arthur Fleck, from aspiring stand-...   \n",
       "88  In the slums of Rio, two kids' paths diverge a...   \n",
       "\n",
       "                                 justwatch_name  \\\n",
       "0       harry-potter-and-the-philosophers-stone   \n",
       "1                            mission-impossible   \n",
       "2                                 the-godfather   \n",
       "3   harry-potter-and-the-deathly-hallows-part-2   \n",
       "4                                        aliens   \n",
       "..                                          ...   \n",
       "84                           lawrence-of-arabia   \n",
       "85                               paths-of-glory   \n",
       "86                                       oldboy   \n",
       "87                                        joker   \n",
       "88                                  city-of-god   \n",
       "\n",
       "                                       justwatch_snps  \n",
       "0   Harry Potter has lived under the stairs at his...  \n",
       "1   When Ethan Hunt, the leader of a crack espiona...  \n",
       "2   Spanning the years 1945 to 1955, a chronicle o...  \n",
       "3   Harry, Ron and Hermione continue their quest t...  \n",
       "4   Two young boys discuss their favorite movies a...  \n",
       "..                                                ...  \n",
       "84  The story of British officer T.E. Lawrence's m...  \n",
       "85  A commanding officer defends three scapegoats ...  \n",
       "86  An everyday man has only three and a half days...  \n",
       "87  Mannar Mannan, an ordinary villager, decides t...  \n",
       "88  In the slums of Rio, two kids' paths diverge a...  \n",
       "\n",
       "[89 rows x 9 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_jw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29de63e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅Sent: Harry Potter and the Sorcerer's Stone \tPredicted: Harry Potter and the Sorcerer's Stone\n",
      "✅Sent: Mission: Impossible \tPredicted: Mission: Impossible\n",
      "✅Sent: The Godfather \tPredicted: The Godfather\n",
      "❌Sent: Harry Potter and the Deathly Hallows: Part 2 \tPredicted: Harry Potter and the Sorcerer's Stone\n",
      "❌Sent: Aliens \tPredicted: Singin' in the Rain\n",
      "✅Sent: Apocalypse Now \tPredicted: Apocalypse Now\n",
      "✅Sent: Avengers: Endgame \tPredicted: Avengers: Endgame\n",
      "❌Sent: The Lord of the Rings: The Return of the King \tPredicted: The Lord of the Rings: The Fellowship of the Ring\n",
      "\n",
      "\n",
      ">>>>ERROR ON  sunset-blvd nan\n",
      "✅Sent: Django Unchained \tPredicted: Django Unchained\n",
      "✅Sent: The Usual Suspects \tPredicted: The Usual Suspects\n",
      "❌Sent: Rear Window \tPredicted: M\n",
      "❌Sent: The Good, the Bad and the Ugly \tPredicted: Come and See\n",
      "❌Sent: Pulp Fiction \tPredicted: Once Upon a Time in the West\n",
      "❌Sent: Whiplash \tPredicted: The Lives of Others\n",
      "❌Sent: 12 Angry Men \tPredicted: Witness for the Prosecution\n",
      "✅Sent: Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb \tPredicted: Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb\n",
      "✅Sent: It's a Wonderful Life \tPredicted: It's a Wonderful Life\n",
      "❌Sent: Psycho \tPredicted: Singin' in the Rain\n",
      "✅Sent: The Silence of the Lambs \tPredicted: The Silence of the Lambs\n",
      "❌Sent: Star Wars: Episode IV - A New Hope \tPredicted: Star Wars: Episode VI - Return of the Jedi\n",
      "❌Sent: Star Wars: Episode V - The Empire Strikes Back \tPredicted: Star Wars: Episode VI - Return of the Jedi\n",
      "❌Sent: 2001: A Space Odyssey \tPredicted: WALL·E\n",
      "❌Sent: Terminator 2: Judgment Day \tPredicted: The Godfather\n",
      "❌Sent: Back to the Future \tPredicted: Once Upon a Time in America\n",
      "✅Sent: Saving Private Ryan \tPredicted: Saving Private Ryan\n",
      "❌Sent: Memento \tPredicted: Oldboy\n",
      "❌Sent: The Dark Knight Rises \tPredicted: The Silence of the Lambs\n",
      "✅Sent: M \tPredicted: M\n",
      "\n",
      "\n",
      ">>>>ERROR ON  walle nan\n",
      "✅Sent: Star Wars: Episode VI - Return of the Jedi \tPredicted: Star Wars: Episode VI - Return of the Jedi\n",
      "✅Sent: Seven Samurai \tPredicted: Seven Samurai\n",
      "✅Sent: Braveheart \tPredicted: Braveheart\n",
      "❌Sent: Avengers: Infinity War \tPredicted: Avengers: Endgame\n",
      "❌Sent: American History X \tPredicted: The Usual Suspects\n",
      "✅Sent: Grave of the Fireflies \tPredicted: Grave of the Fireflies\n",
      "❌Sent: Once Upon a Time in America \tPredicted: The Pianist\n",
      "❌Sent: Toy Story \tPredicted: Toy Story 3\n",
      "✅Sent: High and Low \tPredicted: High and Low\n",
      "\n",
      "\n",
      ">>>>ERROR ON  spiderman-into-the-spiderverse nan\n",
      "❌Sent: Gladiator \tPredicted: American History X\n",
      "❌Sent: The Lord of the Rings: The Fellowship of the Ring \tPredicted: The Lord of the Rings: The Two Towers\n",
      "✅Sent: Eternal Sunshine of the Spotless Mind \tPredicted: Eternal Sunshine of the Spotless Mind\n",
      "✅Sent: The Great Dictator \tPredicted: The Great Dictator\n",
      "❌Sent: Come and See \tPredicted: Seven Samurai\n",
      "❌Sent: Parasite \tPredicted: Mission: Impossible\n",
      "❌Sent: Alien \tPredicted: WALL·E\n",
      "❌Sent: Schindler's List \tPredicted: Come and See\n",
      "✅Sent: Amadeus \tPredicted: Amadeus\n",
      "❌Sent: The Departed \tPredicted: The Usual Suspects\n",
      "❌Sent: Goodfellas \tPredicted: The Godfather Part II\n",
      "❌Sent: The Prestige \tPredicted: The Lord of the Rings: The Two Towers\n",
      "❌Sent: Das Boot \tPredicted: Apocalypse Now\n",
      "✅Sent: Witness for the Prosecution \tPredicted: Witness for the Prosecution\n",
      "✅Sent: Se7en \tPredicted: Se7en\n",
      "✅Sent: Coco \tPredicted: Coco\n",
      "✅Sent: Your Name. \tPredicted: Your Name.\n",
      "❌Sent: The Intouchables \tPredicted: The Usual Suspects\n",
      "✅Sent: Toy Story 3 \tPredicted: Toy Story 3\n",
      "❌Sent: Life Is Beautiful \tPredicted: The Great Dictator\n",
      "❌Sent: Interstellar \tPredicted: WALL·E\n",
      "❌Sent: Harakiri \tPredicted: The Intouchables\n",
      "❌Sent: North by Northwest \tPredicted: Goodfellas\n",
      "\n",
      "\n",
      ">>>>ERROR ON  spiderman-across-the-spiderverse nan\n",
      "\n",
      "\n",
      ">>>>ERROR ON  indiana-jones-and-the-raiders-of-the-lost-ark nan\n",
      "✅Sent: The Green Mile \tPredicted: The Green Mile\n",
      "✅Sent: Princess Mononoke \tPredicted: Princess Mononoke\n",
      "❌Sent: The Matrix \tPredicted: Avengers: Endgame\n",
      "✅Sent: Reservoir Dogs \tPredicted: Reservoir Dogs\n",
      "✅Sent: Citizen Kane \tPredicted: Citizen Kane\n",
      "✅Sent: Singin' in the Rain \tPredicted: Singin' in the Rain\n",
      "❌Sent: Casablanca \tPredicted: Lawrence of Arabia\n",
      "❌Sent: Once Upon a Time in the West \tPredicted: WALL·E\n",
      "❌Sent: Spirited Away \tPredicted: Your Name.\n",
      "❌Sent: The Dark Knight \tPredicted: The Great Dictator\n",
      "❌Sent: Inglourious Basterds \tPredicted: Come and See\n",
      "❌Sent: The Lion King \tPredicted: Seven Samurai\n",
      "❌Sent: The Lord of the Rings: The Two Towers \tPredicted: The Lord of the Rings: The Fellowship of the Ring\n",
      "❌Sent: Inception \tPredicted: The Lives of Others\n",
      "✅Sent: The Lives of Others \tPredicted: The Lives of Others\n",
      "✅Sent: The Godfather Part II \tPredicted: The Godfather Part II\n",
      "✅Sent: The Pianist \tPredicted: The Pianist\n",
      "\n",
      "\n",
      ">>>>ERROR ON  léon-the-professional nan\n",
      "❌Sent: The Shining \tPredicted: It's a Wonderful Life\n",
      "✅Sent: Lawrence of Arabia \tPredicted: Lawrence of Arabia\n",
      "❌Sent: Paths of Glory \tPredicted: Apocalypse Now\n",
      "❌Sent: Oldboy \tPredicted: 12 Angry Men\n",
      "❌Sent: Joker \tPredicted: The Great Dictator\n",
      "❌Sent: City of God \tPredicted: Once Upon a Time in the West\n",
      "\n",
      "\n",
      "Total found  34 of 83 40.963855421686745 %\n"
     ]
    }
   ],
   "source": [
    "matches=0\n",
    "fails=0\n",
    "for i,  name in df_jw.iterrows():\n",
    "    if(type(name['justwatch_snps'])!=str):\n",
    "        print(\"\\n\\n>>>>ERROR ON \",name['justwatch_name'],name['justwatch_snps'])\n",
    "        fails=fails+1\n",
    "        continue\n",
    "    _summary=name['justwatch_snps']\n",
    "    _match=find_similar_movie(_summary)\n",
    "    if(name['name'] == _match['name']):\n",
    "        matches=matches+1\n",
    "        print(\"✅\", end=\"\")\n",
    "    else:\n",
    "        print(\"❌\", end=\"\")\n",
    "    print(\"Sent:\",name['name'] ,\"\\tPredicted:\", _match['name'])\n",
    "print(\"\\n\\nTotal found \",matches,'of',len(df_jw)-fails , (matches*100/(len(df_jw)-fails)), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efffb497",
   "metadata": {},
   "source": [
    "#  \n",
    "# =============================  \n",
    "# Approach2\n",
    "# =============================  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfa2a2c",
   "metadata": {},
   "source": [
    "# Spacy\n",
    "Tokenize and process your summary and dataset records using spaCy.  \n",
    "Extract features or embeddings from the text, such as word vectors.  \n",
    "Calculate the similarity between the summary and each dataset record using cosine similarity or other distance metrics.  \n",
    "Sort the records based on their similarity scores to find the most similar one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1fbda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=nlp(\"Sir Ethan Hunt is a member of MI6\")\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5dca6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "#python -m spacy download en_core_web_lg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74a7554",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5f1667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aa60ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_scores[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e650e2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c323a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset_raw\n",
    "dataset_docs = [nlp(record) for record in dataset]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a191098",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(similarity_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f23a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = summary_raw_hp2\n",
    "summary_doc = nlp(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "154138a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_scores = [summary_doc.similarity(doc) for doc in dataset_docs]\n",
    "\n",
    "most_similar_index = similarity_scores.index(max(similarity_scores))\n",
    "most_similar_record = dataset[most_similar_index]\n",
    "\n",
    "\n",
    "print(\"Given Synopsis is:\", summary,'\\n')\n",
    "most_similar_record[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e318e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9888758c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85203276",
   "metadata": {},
   "source": [
    "# NLTK\n",
    "Preprocess your summary and dataset records using NLTK's tokenization, stemming, or other text processing functions.  \n",
    "Represent the texts using appropriate numerical representations such as TF-IDF (Term Frequency-Inverse Document Frequency).  \n",
    "Compute the similarity between the summary and each dataset record using measures like cosine similarity, Jaccard similarity, or other similarity metrics available in NLTK.  \n",
    "Sort the records based on their similarity scores to find the most similar one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2469609f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.metrics.distance import edit_distance\n",
    "from nltk.metrics.distance import jaccard_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43427c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary = \"This is the summary of the text.\"\n",
    "# dataset = [\"Record 1\", \"Record 2\", ..., \"Record 100000\"]\n",
    "\n",
    "# Tokenize the summary\n",
    "summary_tokens = word_tokenize(summary.lower())\n",
    "\n",
    "# Remove stopwords from the summary\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "summary_filtered = [token for token in summary_tokens if token not in stop_words]\n",
    "\n",
    "# Lemmatize the summary\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "summary_lemmatized = [lemmatizer.lemmatize(token) for token in summary_filtered]\n",
    "\n",
    "# Tokenize, remove stopwords, and lemmatize the dataset records\n",
    "dataset_filtered = []\n",
    "for record in dataset_clean_text:\n",
    "    record_tokens = word_tokenize(record.lower())\n",
    "    record_filtered = [token for token in record_tokens if token not in stop_words]\n",
    "    record_lemmatized = [lemmatizer.lemmatize(token) for token in record_filtered]\n",
    "    dataset_filtered.append(record_lemmatized)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dfd790",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_scores = []\n",
    "for record in dataset_filtered:\n",
    "    # Calculate the similarity using the Jaccard distance\n",
    "    similarity = 1 - jaccard_distance(set(summary_lemmatized), set(record))\n",
    "    similarity_scores.append(similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861cdd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_index = similarity_scores.index(max(similarity_scores))\n",
    "most_similar_record = dataset_clean_text[most_similar_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3777ee2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3efe99ee",
   "metadata": {},
   "source": [
    "# GENSIM\n",
    "Preprocess your summary and dataset records using tokenization, stemming, or other techniques available in gensim or NLTK.  \n",
    "Train or load a Word2Vec model using gensim to generate word embeddings.  \n",
    "Compute the sentence or document embeddings by averaging or pooling the word embeddings.  \n",
    "Calculate the similarity between the summary and each dataset record using cosine similarity or other similarity measures available in gensim.  \n",
    "Rank the records based on their similarity scores to identify the most similar one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52ddbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec, Doc2Vec\n",
    "from gensim import corpora\n",
    "from gensim.similarities import MatrixSimilarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412e55a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary = \"This is the summary of the text.\"\n",
    "# dataset = [\"Record 1\", \"Record 2\", ..., \"Record 100000\"]\n",
    "\n",
    "summary_raw_hp2 = \"In this movie Ginny open it with a diary, and there is a big snake. Emma Watson as hermione, ron help Harry to defend from Voldemort, also Harry can talk to it in the girls bathroom. \"\n",
    "summary_raw_hp8 = \"In this movie Harry have destroyed most Horcruxes, and he Hermione and Ron Have to fight Voldemort. There is a huge battle of wizards in the castle of Hogwarts. Weasly die in the fight, but one twin lose his ear. \"\n",
    "summary_raw_gf='a gangster try to get into a family business,Corleone with the italians. they are in the mafia family, the head of the Corleone Mafia family '\n",
    "summary_raw_mi=\" the IMF agent Ethan Hunt gets bretrayed and have to steal the noc list.\"\n",
    "dataset_gensim = df['description'].tolist()\n",
    "summary=summary_raw_hp8\n",
    "\n",
    "# Tokenize the summary\n",
    "summary_tokens = gensim.utils.simple_preprocess(summary.lower())\n",
    "\n",
    "# Tokenize the dataset records\n",
    "dataset_tokens = [gensim.utils.simple_preprocess(record.lower()) for record in dataset_gensim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698bb761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Word2Vec(dataset_tokens, min_count=1) #, size=100\n",
    "model = Doc2Vec(word_tokenize(dataset_tokens[0]), min_count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77358c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_embedding = model.infer_vector(summary_tokens)\n",
    "dataset_embeddings = [model.infer_vector(tokens) for tokens in dataset_tokens]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6cebe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [summary_embedding] + dataset_embeddings\n",
    "index = MatrixSimilarity(corpus)\n",
    "\n",
    "similarity_scores = index[summary_embedding]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1743db",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_similar_index = similarity_scores.argmax()\n",
    "most_similar_record = dataset_gensim[most_similar_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c7e6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "\n",
    "# Assuming you have a list of documents, where each document is a list of words\n",
    "documents = [['word1', 'word2', 'word3'], ['word4', 'word5', 'word6'], ['word7', 'word8', 'word9']]\n",
    "\n",
    "# Prepare tagged documents for training\n",
    "tagged_documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(documents)]\n",
    "\n",
    "# Train the Doc2Vec model\n",
    "model = Doc2Vec(tagged_documents, vector_size=100, epochs=10)\n",
    "\n",
    "# Infer a vector for a new document\n",
    "new_document = ['word10', 'word11', 'word12']\n",
    "vector = model.infer_vector(new_document)\n",
    "\n",
    "# Find the most similar documents\n",
    "similar_documents = model.docvecs.most_similar(positive=[vector], topn=1)\n",
    "\n",
    "# Retrieve the most similar document index\n",
    "most_similar_index = similar_documents[0][0]\n",
    "\n",
    "# Retrieve the most similar document from the list\n",
    "most_similar_document = documents[most_similar_index]\n",
    "\n",
    "print(\"Most similar document:\", most_similar_document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e0ede9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "48197fd0",
   "metadata": {},
   "source": [
    "# Fuzzy Wuzzy\n",
    " FuzzyWuzzy is a string matching library in Python that provides various methods for fuzzy string comparison. While it may not be as comprehensive as using NLP libraries like spaCy or NLTK, it can still be useful for certain text similarity tasks. \n",
    " Please note that FuzzyWuzzy primarily focuses on string matching based on character-level similarities and may not capture semantic meaning as effectively as NLP-based approaches. \n",
    " Here's an example of how you can use FuzzyWuzzy for identifying similar movie synopses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cb124d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fuzzywuzzy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6cb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz, process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8b988a",
   "metadata": {},
   "outputs": [],
   "source": [
    "synopses = [\n",
    "    \"In a galaxy far, far away...\",\n",
    "    \"A group of friends embark on an adventure...\",\n",
    "    \"Two detectives investigate a series of crimes...\",\n",
    "    # Add more synopses here\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e1951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar_synopsis(query_synopsis, synopses_list):\n",
    "    similarity_scores = []\n",
    "    for synopsis in synopses_list:\n",
    "        similarity = fuzz.token_set_ratio(query_synopsis, synopsis)\n",
    "        similarity_scores.append(similarity)\n",
    "    most_similar_index = similarity_scores.index(max(similarity_scores))\n",
    "    most_similar_synopsis = synopses_list[most_similar_index]\n",
    "    return most_similar_synopsis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5372d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"A group of friends embark on a space journey...\"\n",
    "most_similar = find_most_similar_synopsis(query, synopses)\n",
    "print(most_similar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b632de83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225c9dd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5204b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e89451",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
